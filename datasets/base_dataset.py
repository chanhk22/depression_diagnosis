# 공통 Dataset/Collate

# datasets/base_dataset.py
import os
import yaml
import torch
import numpy as np
from torch.utils.data import Dataset
from torch.nn.utils.rnn import pad_sequence

def load_cfg(path="configs/default.yaml"):
    with open(path, "r") as f:
        return yaml.safe_load(f)

def pad_numpy_to_tensor(arr, pad_len=None):
    # arr: (T, D)
    t = torch.tensor(arr, dtype=torch.float32)
    return t

def collate_windows(batch):
    """
    batch: list of samples where each sample is dict {'audio':Tensor(Ta,D), 'visual':Tensor(Tv,Dv), 'label':int/float (optional)}
    We'll pad time dimension to max length in batch independently for audio and visual.
    """
    auds = [b['audio'] if isinstance(b['audio'], torch.Tensor) else torch.tensor(b['audio'], dtype=torch.float32) for b in batch]
    vids = [b['visual'] if isinstance(b['visual'], torch.Tensor) else torch.tensor(b['visual'], dtype=torch.float32) for b in batch]

    # pad_sequence expects list of (T, D) but will pad on T dimension (first)
    aud_lens = [a.shape[0] for a in auds]
    vid_lens = [v.shape[0] for v in vids]

    # pad to same T along dim0
    auds_padded = pad_sequence(auds, batch_first=True)  # (B, Tmax_aud, D)
    vids_padded = pad_sequence(vids, batch_first=True)  # (B, Tmax_vid, Dv)

    out = {
        "audio": auds_padded,
        "audio_lens": torch.tensor(aud_lens, dtype=torch.long),
        "visual": vids_padded,
        "visual_lens": torch.tensor(vid_lens, dtype=torch.long),
    }
    # labels if present
    if 'label' in batch[0]:
        labels = torch.tensor([b['label'] for b in batch], dtype=torch.float32)
        out['label'] = labels
    if 'phq_score' in batch[0]:
        scores = torch.tensor([b.get('phq_score', 0.0) for b in batch], dtype=torch.float32)
        out['phq_score'] = scores
    # meta
    out['meta'] = [b.get('meta', {}) for b in batch]
    return out

class BaseWindowDataset(Dataset):
    """
    Generic dataset reading .npz window files with keys: 'audio', 'visual', optionally others.
    index_csv: CSV with columns ['session','w','t0','t1','path'] generated by window_cache.build_session_windows
    label_map: function(session_id)-> dict {'label':0/1, 'phq_score':float}
    """
    def __init__(self, index_csv, label_map=None, transform=None):
        import pandas as pd
        self.df = pd.read_csv(index_csv)
        self.label_map = label_map
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        npz = np.load(row['path'], allow_pickle=True)
        sample = {}
        # audio
        if 'audio' in npz:
            sample['audio'] = npz['audio'].astype(np.float32)
        else:
            sample['audio'] = np.zeros((1,25), dtype=np.float32)
        # visual - various names: visual, openface, lmk
        if 'visual' in npz:
            sample['visual'] = npz['visual'].astype(np.float32)
        elif 'openface' in npz:
            sample['visual'] = npz['openface'].astype(np.float32)
        elif 'landmarks' in npz:
            sample['visual'] = npz['landmarks'].astype(np.float32)
        else:
            sample['visual'] = np.zeros((1,136), dtype=np.float32)
        # meta
        sample['meta'] = {"session":row['session'], "w": int(row['w']), "t0":float(row['t0']), "t1":float(row['t1'])}
        # labels
        if self.label_map:
            lbls = self.label_map(row['session'])
            if lbls is not None:
                if 'label' in lbls:
                    sample['label'] = lbls['label']
                if 'phq_score' in lbls:
                    sample['phq_score'] = lbls['phq_score']
        if self.transform:
            sample = self.transform(sample)
        return sample
